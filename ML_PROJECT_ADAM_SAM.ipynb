{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Modeling U.S Gun-Homcide Rates using SVI\n",
        "###A comprehensive analysis by Adam Sam\n",
        "\n",
        "<img src=\"https://www.bridgemi.com/sites/default/files/styles/full_width_image/public/2022-05/gun%20shutterstock.jpg?itok=AUziubj7\" width=\"520\" height=\"300\">\n",
        "\n"
      ],
      "metadata": {
        "id": "J0UngvoU0Bu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Datasets\n",
        "Gun homicide: https://wonder.cdc.gov/controller/saved/D158/D429F689\n",
        "\n",
        "SVI: https://www.atsdr.cdc.gov/place-health/php/svi/index.html\n",
        "\n",
        "**-Are there correlations between features?**\n",
        "\n",
        "The dataset includes multiple features grouped into four themes: Socioeconomic Status, Household Characteristics, Racial & Ethnic Minority Status, and Housing Type & Transportation.\n",
        "\n",
        "Features like poverty (EP_POV150),unemployment (EP_UNEMP), and lack of high school diploma (EP_NOHSDP) could likely be positively correlated.\n",
        "\n",
        "Features such as elderly population (EP_AGE65) and disability (EP_DISABL) may also be correlated.\n",
        "\n",
        "Variables starting with \"RPL_\" represent the final overall social vulnerability rankings calculated based on the preceding determining variables (non-RPL variables). These are likely correlated with said variables, and will be separated.\n",
        "\n",
        "A correlation matrix could quantitatively confirm these relationships.\n",
        "\n",
        "**-Are there outliers?**\n",
        "Washington D.C may be an outlier, as it has the highest homicide rate of 21 per 100k.\n",
        "\n",
        "Some other interesting outliers:\n",
        "EP_MINRTY (percentage who are considered minorities): Hawaii (73.76) and D.C (63.7) are much higher than the average.\n",
        "\n",
        "EP_UNINSUR (percentage who are uninsured): Texas (17.41) and Oklahoma (15.16) are outliers compared to states like Massachusetts (3.01).\n",
        "\n",
        "**-Will all features be used? Why or why not?**\n",
        "\n",
        "Not all features in the dataset were used, as some were deemed as adjunct, or irrelevant for measuring social vulnerability; particularly measures of ethnicity composition.\n",
        "\n",
        "The following variables are labeled as adjunct:\n",
        "\n",
        "-estimate of daytime population derived from LandScan 2021 estimates\n",
        "\n",
        "-ACS estimates for households without an internet subscription\n",
        "\n",
        "-ACS estimates for Hispanic/Latino persons, Not Hispanic or Latino Black/African American persons, Not Hispanic or Latino Asian persons, Not\n",
        "Hispanic or Latino American Indian and Alaska Native persons, Not Hispanic or Latino Native Hawaiian and Other Pacific Islander persons, Not Hispanic\n",
        "or Latino persons of two or more races, and Not Hispanic or Latino persons of some other race\n",
        "\n",
        "Variables that are not percentages were not used (raw values). Only the variables starting with \"EP_\" were used, as they represent percentages.\n",
        "\n",
        "Variables starting with \"RPL_\" represent the final overall social vulnerability rankings calculated based on the preceding determining variables (non-RPL variables). These are likely correlated with said varaibles, and will be separated.\n",
        "\n",
        "The RPL_THEMES feature is of main interest, as it is a ranking between 0 and 1 measuring social vulnerability considering all themes (socialeconomic, household, racial, transportation).\n",
        "\n",
        "RPL_THEME1 to RPL_THEME4 are separate rankings for individual layers of the SVI hierarchy.\n",
        "\n",
        "**-Is the dataset balanced?**\n",
        "The dataset appears balanced in terms of geographic representation, as it includes all U.S. states and counties with consistent metrics. However, balance depends on the context:\n",
        "\n",
        "However, the homicide rate per 100k varies widely (example: 1.28 in New Hampshire vs. 20.99 in D.C.), suggesting potential skewness. This could indicate imbalance if modeling homicide rates.\n",
        "\n",
        "**-What feature engineering is needed?**\n",
        "\n",
        "-Manually calculating homicide rate for rows where it is \"Unreliable.\"\n",
        "\n",
        "-Scaling the data using min=max scaling.\n",
        "\n",
        "-Dimensionality reduction using PCA\n",
        "\n",
        "**-Preprocessing steps**\n",
        "\n",
        "-Grouping the data by states\n",
        "\n",
        "-Replacing \"Unreliable\" values within death rate column with the proper values by manually calculating Deaths / Population * 100k.\n",
        "\n",
        "-Irrelevant columns were removed, including:\n",
        "\n",
        "*   Flags representing states fell within a certain category (0 or 1)\n",
        "*   Extraneous state codes and abbreviations\n",
        "*   Exact margin of error values\n",
        "*   Miscellaneous information not used in the measurement of SVI (ethnicity composition)"
      ],
      "metadata": {
        "id": "ZdIPxb7Y30_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DATASET LOADING"
      ],
      "metadata": {
        "id": "MGNR2nh2er_y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "2oDMdhzMz-3L",
        "outputId": "ecab6653-b0b8-4215-ee09-2847d43dd686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The memory_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext memory_profiler\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   EP_POV150  EP_UNEMP   EP_HBURD  EP_NOHSDP  EP_UNINSUR   EP_AGE65  \\\n",
              "0  29.850746  5.905970  22.014925  15.489552    9.804478  19.061194   \n",
              "1  20.593333  7.893333  17.406667   8.780000   15.680000  14.456667   \n",
              "2  28.013333  7.146667  22.926667  13.900000   11.333333  21.880000   \n",
              "3  31.020000  5.973333  22.014667  13.812000    8.330667  19.936000   \n",
              "4  21.489655  6.765517  28.112069  14.094828    6.887931  18.608621   \n",
              "\n",
              "    EP_AGE17  EP_DISABL  EP_SNGPNT  EP_LIMENG  ...  EP_MOBILE   EP_CROWD  \\\n",
              "0  21.622388  19.011940   6.911940   0.822388  ...  21.141791   1.613433   \n",
              "1  23.646667  14.080000   6.016667   1.970000  ...   5.250000  10.753333   \n",
              "2  22.106667  16.086667   6.273333   4.686667  ...  20.173333   5.913333   \n",
              "3  22.144000  20.978667   6.780000   1.081333  ...  16.174667   2.529333   \n",
              "4  21.793103  13.675862   5.603448   6.181034  ...   7.115517   5.760345   \n",
              "\n",
              "    EP_NOVEH  EP_GROUPQ  RPL_THEME1  RPL_THEME2  RPL_THEME3  RPL_THEME4  \\\n",
              "0   6.574627   2.894030    0.693924    0.625413    0.674607    0.531418   \n",
              "1  21.553333   9.890000    0.478500    0.358120    0.832597    0.805073   \n",
              "2   5.826667   3.180000    0.749767    0.752953    0.839607    0.787700   \n",
              "3   6.849333   3.348000    0.673488    0.725617    0.560131    0.593488   \n",
              "4   5.698276   3.327586    0.631514    0.551059    0.802922    0.709186   \n",
              "\n",
              "   RPL_THEMES  Homicide Rate Per 100k  \n",
              "0    0.671582               12.297272  \n",
              "1    0.604770                5.589006  \n",
              "2    0.829213                6.658335  \n",
              "3    0.690255                9.521818  \n",
              "4    0.690778                4.294205  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EP_POV150</th>\n",
              "      <th>EP_UNEMP</th>\n",
              "      <th>EP_HBURD</th>\n",
              "      <th>EP_NOHSDP</th>\n",
              "      <th>EP_UNINSUR</th>\n",
              "      <th>EP_AGE65</th>\n",
              "      <th>EP_AGE17</th>\n",
              "      <th>EP_DISABL</th>\n",
              "      <th>EP_SNGPNT</th>\n",
              "      <th>EP_LIMENG</th>\n",
              "      <th>...</th>\n",
              "      <th>EP_MOBILE</th>\n",
              "      <th>EP_CROWD</th>\n",
              "      <th>EP_NOVEH</th>\n",
              "      <th>EP_GROUPQ</th>\n",
              "      <th>RPL_THEME1</th>\n",
              "      <th>RPL_THEME2</th>\n",
              "      <th>RPL_THEME3</th>\n",
              "      <th>RPL_THEME4</th>\n",
              "      <th>RPL_THEMES</th>\n",
              "      <th>Homicide Rate Per 100k</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29.850746</td>\n",
              "      <td>5.905970</td>\n",
              "      <td>22.014925</td>\n",
              "      <td>15.489552</td>\n",
              "      <td>9.804478</td>\n",
              "      <td>19.061194</td>\n",
              "      <td>21.622388</td>\n",
              "      <td>19.011940</td>\n",
              "      <td>6.911940</td>\n",
              "      <td>0.822388</td>\n",
              "      <td>...</td>\n",
              "      <td>21.141791</td>\n",
              "      <td>1.613433</td>\n",
              "      <td>6.574627</td>\n",
              "      <td>2.894030</td>\n",
              "      <td>0.693924</td>\n",
              "      <td>0.625413</td>\n",
              "      <td>0.674607</td>\n",
              "      <td>0.531418</td>\n",
              "      <td>0.671582</td>\n",
              "      <td>12.297272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.593333</td>\n",
              "      <td>7.893333</td>\n",
              "      <td>17.406667</td>\n",
              "      <td>8.780000</td>\n",
              "      <td>15.680000</td>\n",
              "      <td>14.456667</td>\n",
              "      <td>23.646667</td>\n",
              "      <td>14.080000</td>\n",
              "      <td>6.016667</td>\n",
              "      <td>1.970000</td>\n",
              "      <td>...</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>10.753333</td>\n",
              "      <td>21.553333</td>\n",
              "      <td>9.890000</td>\n",
              "      <td>0.478500</td>\n",
              "      <td>0.358120</td>\n",
              "      <td>0.832597</td>\n",
              "      <td>0.805073</td>\n",
              "      <td>0.604770</td>\n",
              "      <td>5.589006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28.013333</td>\n",
              "      <td>7.146667</td>\n",
              "      <td>22.926667</td>\n",
              "      <td>13.900000</td>\n",
              "      <td>11.333333</td>\n",
              "      <td>21.880000</td>\n",
              "      <td>22.106667</td>\n",
              "      <td>16.086667</td>\n",
              "      <td>6.273333</td>\n",
              "      <td>4.686667</td>\n",
              "      <td>...</td>\n",
              "      <td>20.173333</td>\n",
              "      <td>5.913333</td>\n",
              "      <td>5.826667</td>\n",
              "      <td>3.180000</td>\n",
              "      <td>0.749767</td>\n",
              "      <td>0.752953</td>\n",
              "      <td>0.839607</td>\n",
              "      <td>0.787700</td>\n",
              "      <td>0.829213</td>\n",
              "      <td>6.658335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.020000</td>\n",
              "      <td>5.973333</td>\n",
              "      <td>22.014667</td>\n",
              "      <td>13.812000</td>\n",
              "      <td>8.330667</td>\n",
              "      <td>19.936000</td>\n",
              "      <td>22.144000</td>\n",
              "      <td>20.978667</td>\n",
              "      <td>6.780000</td>\n",
              "      <td>1.081333</td>\n",
              "      <td>...</td>\n",
              "      <td>16.174667</td>\n",
              "      <td>2.529333</td>\n",
              "      <td>6.849333</td>\n",
              "      <td>3.348000</td>\n",
              "      <td>0.673488</td>\n",
              "      <td>0.725617</td>\n",
              "      <td>0.560131</td>\n",
              "      <td>0.593488</td>\n",
              "      <td>0.690255</td>\n",
              "      <td>9.521818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21.489655</td>\n",
              "      <td>6.765517</td>\n",
              "      <td>28.112069</td>\n",
              "      <td>14.094828</td>\n",
              "      <td>6.887931</td>\n",
              "      <td>18.608621</td>\n",
              "      <td>21.793103</td>\n",
              "      <td>13.675862</td>\n",
              "      <td>5.603448</td>\n",
              "      <td>6.181034</td>\n",
              "      <td>...</td>\n",
              "      <td>7.115517</td>\n",
              "      <td>5.760345</td>\n",
              "      <td>5.698276</td>\n",
              "      <td>3.327586</td>\n",
              "      <td>0.631514</td>\n",
              "      <td>0.551059</td>\n",
              "      <td>0.802922</td>\n",
              "      <td>0.709186</td>\n",
              "      <td>0.690778</td>\n",
              "      <td>4.294205</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   EP_POV150  EP_UNEMP   EP_HBURD  EP_NOHSDP  EP_UNINSUR   EP_AGE65  \\\n",
              "0  29.850746  5.905970  22.014925  15.489552    9.804478  19.061194   \n",
              "1  20.593333  7.893333  17.406667   8.780000   15.680000  14.456667   \n",
              "2  28.013333  7.146667  22.926667  13.900000   11.333333  21.880000   \n",
              "3  31.020000  5.973333  22.014667  13.812000    8.330667  19.936000   \n",
              "4  21.489655  6.765517  28.112069  14.094828    6.887931  18.608621   \n",
              "\n",
              "    EP_AGE17  EP_DISABL  EP_SNGPNT  EP_LIMENG  ...  EP_MUNIT  EP_MOBILE  \\\n",
              "0  21.622388  19.011940   6.911940   0.822388  ...  3.277612  21.141791   \n",
              "1  23.646667  14.080000   6.016667   1.970000  ...  5.036667   5.250000   \n",
              "2  22.106667  16.086667   6.273333   4.686667  ...  4.800000  20.173333   \n",
              "3  22.144000  20.978667   6.780000   1.081333  ...  3.037333  16.174667   \n",
              "4  21.793103  13.675862   5.603448   6.181034  ...  9.300000   7.115517   \n",
              "\n",
              "    EP_CROWD   EP_NOVEH  EP_GROUPQ  RPL_THEME1  RPL_THEME2  RPL_THEME3  \\\n",
              "0   1.613433   6.574627   2.894030    0.693924    0.625413    0.674607   \n",
              "1  10.753333  21.553333   9.890000    0.478500    0.358120    0.832597   \n",
              "2   5.913333   5.826667   3.180000    0.749767    0.752953    0.839607   \n",
              "3   2.529333   6.849333   3.348000    0.673488    0.725617    0.560131   \n",
              "4   5.760345   5.698276   3.327586    0.631514    0.551059    0.802922   \n",
              "\n",
              "   RPL_THEME4  RPL_THEMES  \n",
              "0    0.531418    0.671582  \n",
              "1    0.805073    0.604770  \n",
              "2    0.787700    0.829213  \n",
              "3    0.593488    0.690255  \n",
              "4    0.709186    0.690778  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EP_POV150</th>\n",
              "      <th>EP_UNEMP</th>\n",
              "      <th>EP_HBURD</th>\n",
              "      <th>EP_NOHSDP</th>\n",
              "      <th>EP_UNINSUR</th>\n",
              "      <th>EP_AGE65</th>\n",
              "      <th>EP_AGE17</th>\n",
              "      <th>EP_DISABL</th>\n",
              "      <th>EP_SNGPNT</th>\n",
              "      <th>EP_LIMENG</th>\n",
              "      <th>...</th>\n",
              "      <th>EP_MUNIT</th>\n",
              "      <th>EP_MOBILE</th>\n",
              "      <th>EP_CROWD</th>\n",
              "      <th>EP_NOVEH</th>\n",
              "      <th>EP_GROUPQ</th>\n",
              "      <th>RPL_THEME1</th>\n",
              "      <th>RPL_THEME2</th>\n",
              "      <th>RPL_THEME3</th>\n",
              "      <th>RPL_THEME4</th>\n",
              "      <th>RPL_THEMES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29.850746</td>\n",
              "      <td>5.905970</td>\n",
              "      <td>22.014925</td>\n",
              "      <td>15.489552</td>\n",
              "      <td>9.804478</td>\n",
              "      <td>19.061194</td>\n",
              "      <td>21.622388</td>\n",
              "      <td>19.011940</td>\n",
              "      <td>6.911940</td>\n",
              "      <td>0.822388</td>\n",
              "      <td>...</td>\n",
              "      <td>3.277612</td>\n",
              "      <td>21.141791</td>\n",
              "      <td>1.613433</td>\n",
              "      <td>6.574627</td>\n",
              "      <td>2.894030</td>\n",
              "      <td>0.693924</td>\n",
              "      <td>0.625413</td>\n",
              "      <td>0.674607</td>\n",
              "      <td>0.531418</td>\n",
              "      <td>0.671582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.593333</td>\n",
              "      <td>7.893333</td>\n",
              "      <td>17.406667</td>\n",
              "      <td>8.780000</td>\n",
              "      <td>15.680000</td>\n",
              "      <td>14.456667</td>\n",
              "      <td>23.646667</td>\n",
              "      <td>14.080000</td>\n",
              "      <td>6.016667</td>\n",
              "      <td>1.970000</td>\n",
              "      <td>...</td>\n",
              "      <td>5.036667</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>10.753333</td>\n",
              "      <td>21.553333</td>\n",
              "      <td>9.890000</td>\n",
              "      <td>0.478500</td>\n",
              "      <td>0.358120</td>\n",
              "      <td>0.832597</td>\n",
              "      <td>0.805073</td>\n",
              "      <td>0.604770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28.013333</td>\n",
              "      <td>7.146667</td>\n",
              "      <td>22.926667</td>\n",
              "      <td>13.900000</td>\n",
              "      <td>11.333333</td>\n",
              "      <td>21.880000</td>\n",
              "      <td>22.106667</td>\n",
              "      <td>16.086667</td>\n",
              "      <td>6.273333</td>\n",
              "      <td>4.686667</td>\n",
              "      <td>...</td>\n",
              "      <td>4.800000</td>\n",
              "      <td>20.173333</td>\n",
              "      <td>5.913333</td>\n",
              "      <td>5.826667</td>\n",
              "      <td>3.180000</td>\n",
              "      <td>0.749767</td>\n",
              "      <td>0.752953</td>\n",
              "      <td>0.839607</td>\n",
              "      <td>0.787700</td>\n",
              "      <td>0.829213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.020000</td>\n",
              "      <td>5.973333</td>\n",
              "      <td>22.014667</td>\n",
              "      <td>13.812000</td>\n",
              "      <td>8.330667</td>\n",
              "      <td>19.936000</td>\n",
              "      <td>22.144000</td>\n",
              "      <td>20.978667</td>\n",
              "      <td>6.780000</td>\n",
              "      <td>1.081333</td>\n",
              "      <td>...</td>\n",
              "      <td>3.037333</td>\n",
              "      <td>16.174667</td>\n",
              "      <td>2.529333</td>\n",
              "      <td>6.849333</td>\n",
              "      <td>3.348000</td>\n",
              "      <td>0.673488</td>\n",
              "      <td>0.725617</td>\n",
              "      <td>0.560131</td>\n",
              "      <td>0.593488</td>\n",
              "      <td>0.690255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21.489655</td>\n",
              "      <td>6.765517</td>\n",
              "      <td>28.112069</td>\n",
              "      <td>14.094828</td>\n",
              "      <td>6.887931</td>\n",
              "      <td>18.608621</td>\n",
              "      <td>21.793103</td>\n",
              "      <td>13.675862</td>\n",
              "      <td>5.603448</td>\n",
              "      <td>6.181034</td>\n",
              "      <td>...</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>7.115517</td>\n",
              "      <td>5.760345</td>\n",
              "      <td>5.698276</td>\n",
              "      <td>3.327586</td>\n",
              "      <td>0.631514</td>\n",
              "      <td>0.551059</td>\n",
              "      <td>0.802922</td>\n",
              "      <td>0.709186</td>\n",
              "      <td>0.690778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   RPL_THEME1  RPL_THEME2  RPL_THEME3  RPL_THEME4  RPL_THEMES\n",
              "0    0.693924    0.625413    0.674607    0.531418    0.671582\n",
              "1    0.478500    0.358120    0.832597    0.805073    0.604770\n",
              "2    0.749767    0.752953    0.839607    0.787700    0.829213\n",
              "3    0.673488    0.725617    0.560131    0.593488    0.690255\n",
              "4    0.631514    0.551059    0.802922    0.709186    0.690778"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RPL_THEME1</th>\n",
              "      <th>RPL_THEME2</th>\n",
              "      <th>RPL_THEME3</th>\n",
              "      <th>RPL_THEME4</th>\n",
              "      <th>RPL_THEMES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.693924</td>\n",
              "      <td>0.625413</td>\n",
              "      <td>0.674607</td>\n",
              "      <td>0.531418</td>\n",
              "      <td>0.671582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.478500</td>\n",
              "      <td>0.358120</td>\n",
              "      <td>0.832597</td>\n",
              "      <td>0.805073</td>\n",
              "      <td>0.604770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.749767</td>\n",
              "      <td>0.752953</td>\n",
              "      <td>0.839607</td>\n",
              "      <td>0.787700</td>\n",
              "      <td>0.829213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.673488</td>\n",
              "      <td>0.725617</td>\n",
              "      <td>0.560131</td>\n",
              "      <td>0.593488</td>\n",
              "      <td>0.690255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.631514</td>\n",
              "      <td>0.551059</td>\n",
              "      <td>0.802922</td>\n",
              "      <td>0.709186</td>\n",
              "      <td>0.690778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   EP_POV150  EP_UNEMP   EP_HBURD  EP_NOHSDP  EP_UNINSUR   EP_AGE65  \\\n",
              "0  29.850746  5.905970  22.014925  15.489552    9.804478  19.061194   \n",
              "1  20.593333  7.893333  17.406667   8.780000   15.680000  14.456667   \n",
              "2  28.013333  7.146667  22.926667  13.900000   11.333333  21.880000   \n",
              "3  31.020000  5.973333  22.014667  13.812000    8.330667  19.936000   \n",
              "4  21.489655  6.765517  28.112069  14.094828    6.887931  18.608621   \n",
              "\n",
              "    EP_AGE17  EP_DISABL  EP_SNGPNT  EP_LIMENG  EP_MINRTY  EP_MUNIT  EP_MOBILE  \\\n",
              "0  21.622388  19.011940   6.911940   0.822388  36.023881  3.277612  21.141791   \n",
              "1  23.646667  14.080000   6.016667   1.970000  54.526667  5.036667   5.250000   \n",
              "2  22.106667  16.086667   6.273333   4.686667  50.940000  4.800000  20.173333   \n",
              "3  22.144000  20.978667   6.780000   1.081333  26.834667  3.037333  16.174667   \n",
              "4  21.793103  13.675862   5.603448   6.181034  48.439655  9.300000   7.115517   \n",
              "\n",
              "    EP_CROWD   EP_NOVEH  EP_GROUPQ  \n",
              "0   1.613433   6.574627   2.894030  \n",
              "1  10.753333  21.553333   9.890000  \n",
              "2   5.913333   5.826667   3.180000  \n",
              "3   2.529333   6.849333   3.348000  \n",
              "4   5.760345   5.698276   3.327586  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EP_POV150</th>\n",
              "      <th>EP_UNEMP</th>\n",
              "      <th>EP_HBURD</th>\n",
              "      <th>EP_NOHSDP</th>\n",
              "      <th>EP_UNINSUR</th>\n",
              "      <th>EP_AGE65</th>\n",
              "      <th>EP_AGE17</th>\n",
              "      <th>EP_DISABL</th>\n",
              "      <th>EP_SNGPNT</th>\n",
              "      <th>EP_LIMENG</th>\n",
              "      <th>EP_MINRTY</th>\n",
              "      <th>EP_MUNIT</th>\n",
              "      <th>EP_MOBILE</th>\n",
              "      <th>EP_CROWD</th>\n",
              "      <th>EP_NOVEH</th>\n",
              "      <th>EP_GROUPQ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29.850746</td>\n",
              "      <td>5.905970</td>\n",
              "      <td>22.014925</td>\n",
              "      <td>15.489552</td>\n",
              "      <td>9.804478</td>\n",
              "      <td>19.061194</td>\n",
              "      <td>21.622388</td>\n",
              "      <td>19.011940</td>\n",
              "      <td>6.911940</td>\n",
              "      <td>0.822388</td>\n",
              "      <td>36.023881</td>\n",
              "      <td>3.277612</td>\n",
              "      <td>21.141791</td>\n",
              "      <td>1.613433</td>\n",
              "      <td>6.574627</td>\n",
              "      <td>2.894030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.593333</td>\n",
              "      <td>7.893333</td>\n",
              "      <td>17.406667</td>\n",
              "      <td>8.780000</td>\n",
              "      <td>15.680000</td>\n",
              "      <td>14.456667</td>\n",
              "      <td>23.646667</td>\n",
              "      <td>14.080000</td>\n",
              "      <td>6.016667</td>\n",
              "      <td>1.970000</td>\n",
              "      <td>54.526667</td>\n",
              "      <td>5.036667</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>10.753333</td>\n",
              "      <td>21.553333</td>\n",
              "      <td>9.890000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28.013333</td>\n",
              "      <td>7.146667</td>\n",
              "      <td>22.926667</td>\n",
              "      <td>13.900000</td>\n",
              "      <td>11.333333</td>\n",
              "      <td>21.880000</td>\n",
              "      <td>22.106667</td>\n",
              "      <td>16.086667</td>\n",
              "      <td>6.273333</td>\n",
              "      <td>4.686667</td>\n",
              "      <td>50.940000</td>\n",
              "      <td>4.800000</td>\n",
              "      <td>20.173333</td>\n",
              "      <td>5.913333</td>\n",
              "      <td>5.826667</td>\n",
              "      <td>3.180000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.020000</td>\n",
              "      <td>5.973333</td>\n",
              "      <td>22.014667</td>\n",
              "      <td>13.812000</td>\n",
              "      <td>8.330667</td>\n",
              "      <td>19.936000</td>\n",
              "      <td>22.144000</td>\n",
              "      <td>20.978667</td>\n",
              "      <td>6.780000</td>\n",
              "      <td>1.081333</td>\n",
              "      <td>26.834667</td>\n",
              "      <td>3.037333</td>\n",
              "      <td>16.174667</td>\n",
              "      <td>2.529333</td>\n",
              "      <td>6.849333</td>\n",
              "      <td>3.348000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21.489655</td>\n",
              "      <td>6.765517</td>\n",
              "      <td>28.112069</td>\n",
              "      <td>14.094828</td>\n",
              "      <td>6.887931</td>\n",
              "      <td>18.608621</td>\n",
              "      <td>21.793103</td>\n",
              "      <td>13.675862</td>\n",
              "      <td>5.603448</td>\n",
              "      <td>6.181034</td>\n",
              "      <td>48.439655</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>7.115517</td>\n",
              "      <td>5.760345</td>\n",
              "      <td>5.698276</td>\n",
              "      <td>3.327586</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\"\"\" ADAM SAM\n",
        "steps to connect to lambda machine for co-lab\n",
        "1. ssh -L 8888:localhost:8888 sama1@lab.cs.wit.edu -p 50004\n",
        "\n",
        "2. jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com'\n",
        "--port=8888 --NotebookApp.port_retries=0\n",
        "\n",
        "3.\n",
        "On your PC, go to Google Colab and select \"Connect to a local runtime\" (top\n",
        "right corner).\n",
        "\n",
        "In the URL box, enter the URL with the token you received from the output of\n",
        "the Jupyter Notebook command in Step 2.\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%load_ext memory_profiler\n",
        "\n",
        "####MAKE SURE TO CD TO ML_PROJECT DIR FIRST!#####\n",
        "#!cd ML_PROJECT\n",
        "#scp -P 50004 \"C:\\Users\\sama1\\Downloads\\f2\\svi\\SVI_FINAL_CLEAN_2022.csv\" sama1@lab.cs.wit.edu:\"~/ML_PROJECT\"\n",
        "#loading dataset\n",
        "data = pd.read_csv(\"SVI_FINAL_CLEAN_2022.csv\")\n",
        "#data.head()\n",
        "\n",
        "#drop \"Deaths\" and \"Population\" and \"STATE\"\n",
        "data = data.drop([\"STATE\",\"Deaths\", \"Population\"], axis=1)\n",
        "display(data.head())\n",
        "\n",
        "target = data.iloc[:,-1]\n",
        "\n",
        "#display(target)\n",
        "\n",
        "data = data.drop(columns=data.columns[-1])\n",
        "display(data.head())\n",
        "#separate \"RPL_\" columns\n",
        "data_with_ranks = data.loc[:, data.columns.str.startswith('RPL_')]\n",
        "data = data.loc[:, ~data.columns.str.startswith('RPL_')]\n",
        "\n",
        "display(data_with_ranks.head())\n",
        "display(data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL SELECTION BASELINE"
      ],
      "metadata": {
        "id": "fzyaY19yeuYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import time,sys\n",
        "from io import StringIO\n",
        "\n",
        "#BASELINE training on unscaled data!\n",
        "#split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "#linear regression. NOTE: Linear regression has no hyperparameters, so no CV is needed\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "t0 = time.time()\n",
        "%memit lin_reg.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "base_lin_train_time = t1 - t0\n",
        "\n",
        "t0 = time.time()\n",
        "base_y_pred_lin = lin_reg.predict(X_test)\n",
        "t1 = time.time()\n",
        "base_lin_infer_time = t1 - t0\n",
        "#SVR\n",
        "#Cross-validate SVR with GRIDSEARCH\n",
        "param_grid = {'C': np.linspace(0.1, 1, 7), #higher C means less tolerance, lower means more tolerance\n",
        "              'kernel': ['linear', 'rbf', 'poly'],\n",
        "              'degree': [2, 3, 4,5],\n",
        "              'epsilon':np.linspace(0.01, 0.1, 10)}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "t0 = time.time()\n",
        "grid_search = GridSearchCV(SVR(), param_grid, n_jobs=-1,cv=5, verbose=True, scoring = \"neg_root_mean_squared_error\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "base_svr_train_time = t1 - t0\n",
        "\n",
        "svr = grid_search.best_estimator_\n",
        "\n",
        "t0 = time.time()\n",
        "base_y_pred_svr = svr.predict(X_test)\n",
        "t1 = time.time()\n",
        "base_svr_infer_time = t1 - t0\n",
        "\n",
        "print(f\"Best SVR parameters: %s\" % grid_search.best_params_)\n",
        "\n",
        "#XGBoost\n",
        "\"\"\"\n",
        "n_estimators: The number of trees in the ensemble, often increased until no further improvements are seen.\n",
        "max_depth: The maximum depth of each tree, often values are between 1 and 10.\n",
        "eta: The learning rate used to weight each model, often set to small values such as 0.3, 0.1, 0.01, or smaller.\n",
        "subsample: The number of samples (rows) used in each tree, set to a value between 0 and 1, often 1.0 to use all samples.\n",
        "colsample_bytree: Number of features (columns) used in each tree, set to a value between 0 and 1, often 1.0 to use all features.\n",
        "\"\"\"\n",
        "param_grid = {'n_estimators': [300],\n",
        "              'n_jobs':[-1],\n",
        "              'gamma': [1,1.5],\n",
        "              'max_depth': [5,8],\n",
        "              'eta': [0.1,0.3],\n",
        "              'subsample':[1],\n",
        "              'colsample_bytree':[0.75],\n",
        "              'reg_lambda':[0.5,1],\n",
        "              'reg_alpha':[3,2.5],\n",
        "              }\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBRegressor(), param_grid, cv=5, n_jobs=-1,scoring = \"neg_root_mean_squared_error\", verbose=True)\n",
        "t0 = time.time()\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "base_xgb_train_time = t1 - t0\n",
        "\n",
        "xgb_reg = grid_search.best_estimator_\n",
        "\n",
        "t0 = time.time()\n",
        "base_y_pred_xgb = xgb_reg.predict(X_test)\n",
        "t1= time.time()\n",
        "base_xgb_infer_time = t1 - t0\n",
        "\n",
        "print(f\"Best XGBoost parameters:%s\" % grid_search.best_params_)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Riyrk_aYe0HO",
        "outputId": "f4191101-1108-45c2-cc3a-91e6601ef784"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 605.98 MiB, increment: 0.00 MiB\n",
            "Fitting 5 folds for each of 840 candidates, totalling 4200 fits\n",
            "Best SVR parameters: {'C': 0.1, 'degree': 5, 'epsilon': 0.01, 'kernel': 'poly'}\n",
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
            "Best XGBoost parameters:{'colsample_bytree': 0.75, 'eta': 0.3, 'gamma': 1, 'max_depth': 5, 'n_estimators': 300, 'n_jobs': -1, 'reg_alpha': 3, 'reg_lambda': 0.5, 'subsample': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate baseline regression performances\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
        "#lin reg\n",
        "lin_reg_mse = mean_squared_error(y_test, base_y_pred_lin)\n",
        "lin_reg_r2 = r2_score(y_test, base_y_pred_lin)\n",
        "\n",
        "#svr\n",
        "svr_mse = mean_squared_error(y_test, base_y_pred_svr)\n",
        "svr_r2 = r2_score(y_test, base_y_pred_svr)\n",
        "\n",
        "#xgb\n",
        "xgb_mse = mean_squared_error(y_test, base_y_pred_xgb)\n",
        "xgb_r2 = r2_score(y_test, base_y_pred_xgb)\n",
        "\n",
        "#print errors\n",
        "print(f\"Linear Regression MSE: {lin_reg_mse}\")\n",
        "print(f\"Linear Regression R^2: {lin_reg_r2}\")\n",
        "print(f\"SVR MSE: {svr_mse}\")\n",
        "print(f\"SVR R^2: {svr_r2}\")\n",
        "print(f\"XGBoost MSE: {xgb_mse}\")\n",
        "print(f\"XGBoost R^2: {xgb_r2}\")\n",
        "\n",
        "#training times\n",
        "print(f\"Linear Regression Training Time: {base_lin_train_time} seconds\")\n",
        "print(f\"Base SVR Training Time: {base_svr_train_time} seconds\")\n",
        "print(f\"Base XGBoost Training Time: {base_xgb_train_time} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUCup5RZgT_X",
        "outputId": "74ffb8a9-8668-4b86-d904-8c97d195c2a0"
      },
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression MSE: 6.021257024000639\n",
            "Linear Regression R^2: 0.6646905299320609\n",
            "SVR MSE: 6.761787652845931\n",
            "SVR R^2: 0.6234521420443748\n",
            "XGBoost MSE: 5.910049667541645\n",
            "XGBoost R^2: 0.6708834028842183\n",
            "Linear Regression Training Time: 0.6738419532775879 seconds\n",
            "Base SVR Training Time: 2.3886160850524902 seconds\n",
            "Base XGBoost Training Time: 2.0220565795898438 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EXPERIMENT 1: FEATURE SCALING"
      ],
      "metadata": {
        "id": "Xh5Pk4eC6L8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize using minmax()\n",
        "#standard scaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "\n",
        "#SCALE ONLY THE FEATURES!\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "#TRAINING ON SCALED DATA!\n",
        "#linear regression. NOTE: Linear regression has no hyperparameters, so no CV is needed\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "t0 = time.time()\n",
        "%memit lin_reg.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "scale_lin_train_time = t1 - t0\n",
        "\n",
        "t0 = time.time()\n",
        "scale_y_pred_lin = lin_reg.predict(X_test)\n",
        "t1 = time.time()\n",
        "scale_lin_infer_time = t1 - t0\n",
        "\n",
        "#SVR\n",
        "param_grid = {'C': np.linspace(0.1, 1, 7), #higher C means less tolerance, lower means more tolerance\n",
        "              'kernel': ['linear', 'rbf', 'poly'],\n",
        "              'degree': [2, 3, 4,5],\n",
        "              'epsilon':np.linspace(0.01, 0.1, 10)}\n",
        "\n",
        "grid_search = GridSearchCV(SVR(), param_grid, cv=5, n_jobs=-1, verbose=True)\n",
        "\n",
        "t0 = time.time()\n",
        "%memit grid_search.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "scale_svr_train_time = t1 - t0\n",
        "\n",
        "t0 = time.time()\n",
        "scale_y_pred_svr = grid_search.best_estimator_.predict(X_test)\n",
        "t1 = time.time()\n",
        "scale_svr_infer_time = t1 - t0\n",
        "\n",
        "print(f\"Best SVR parameters: %s\" % grid_search.best_params_)\n",
        "\n",
        "#XGBoost\n",
        "\n",
        "param_grid = {'n_estimators': [300],\n",
        "              'n_jobs':[-1],\n",
        "              'gamma': [1,1.5],\n",
        "              'max_depth': [5,8],\n",
        "              'eta': [0.1,0.3],\n",
        "              'subsample':[1],\n",
        "              'colsample_bytree':[0.75],\n",
        "              'reg_lambda':[0.5,1],\n",
        "              'reg_alpha':[3,2.5],\n",
        "              }\n",
        "#Best XGBoost parameters:{'colsample_bytree': 0.75, 'eta': 0.3, 'gamma': 1, 'max_depth': 5, 'n_estimators': 300, 'n_jobs': -1, 'reg_alpha': 3, 'reg_lambda': 0.5, 'subsample': 1}\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBRegressor(), param_grid, n_jobs=-1,cv=5, scoring = \"neg_root_mean_squared_error\", verbose=True)\n",
        "\n",
        "t0 = time.time()\n",
        "%memit grid_search.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "scale_xgb_train_time = t1 - t0\n",
        "\n",
        "t0 = time.time()\n",
        "scale_y_pred_xgb = grid_search.best_estimator_.predict(X_test)\n",
        "t1 = time.time()\n",
        "scale_xgb_infer_time = t1 - t0\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Best XGBoost parameters:%s\" % grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91XxCj5X6JfI",
        "outputId": "a0b62b35-deec-44bf-c786-86ecfacd698c"
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 605.98 MiB, increment: 0.00 MiB\n",
            "Fitting 5 folds for each of 840 candidates, totalling 4200 fits\n",
            "peak memory: 605.98 MiB, increment: 0.00 MiB\n",
            "Best SVR parameters: {'C': 1.0, 'degree': 2, 'epsilon': 0.01, 'kernel': 'linear'}\n",
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
            "peak memory: 605.98 MiB, increment: 0.00 MiB\n",
            "Best XGBoost parameters:{'colsample_bytree': 0.75, 'eta': 0.3, 'gamma': 1, 'max_depth': 5, 'n_estimators': 300, 'n_jobs': -1, 'reg_alpha': 3, 'reg_lambda': 0.5, 'subsample': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate baseline regression performances\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
        "#lin reg\n",
        "scale_lin_reg_mse = mean_squared_error(y_test, scale_y_pred_lin)\n",
        "scale_lin_reg_r2 = r2_score(y_test, scale_y_pred_lin)\n",
        "\n",
        "#svr\n",
        "scale_svr_mse = mean_squared_error(y_test, scale_y_pred_svr)\n",
        "scale_svr_r2 = r2_score(y_test, scale_y_pred_svr)\n",
        "\n",
        "#xgb\n",
        "scale_xgb_mse = mean_squared_error(y_test, scale_y_pred_xgb)\n",
        "scale_xgb_r2 = r2_score(y_test, scale_y_pred_xgb)\n",
        "\n",
        "#print errors\n",
        "print(f\"Linear Regression MSE: {scale_lin_reg_mse}\")\n",
        "print(f\"Linear Regression R^2: {scale_lin_reg_r2}\")\n",
        "print(f\"SVR MSE: {scale_svr_mse}\")\n",
        "print(f\"SVR R^2: {scale_svr_r2}\")\n",
        "print(f\"XGBoost MSE: {scale_xgb_mse}\")\n",
        "print(f\"XGBoost R^2: {scale_xgb_r2}\")\n",
        "\n",
        "#training times\n",
        "print(f\"Scaled Linear Regression Training Time: {scale_lin_train_time} seconds\")\n",
        "print(f\"Scaled SVR Training Time: {scale_svr_train_time} seconds\")\n",
        "print(f\"Scaled XGBoost Training Time: {scale_xgb_train_time} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E11p5bMl-l-Z",
        "outputId": "a3e6ffd1-e139-4d70-88ba-a4690a932a3a"
      },
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression MSE: 6.0212570240006364\n",
            "Linear Regression R^2: 0.6646905299320611\n",
            "SVR MSE: 6.177533595623903\n",
            "SVR R^2: 0.6559878596746443\n",
            "XGBoost MSE: 5.910049667541645\n",
            "XGBoost R^2: 0.6708834028842183\n",
            "Scaled Linear Regression Training Time: 0.6109638214111328 seconds\n",
            "Scaled SVR Training Time: 1.5580792427062988 seconds\n",
            "Scaled XGBoost Training Time: 0.9362764358520508 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"OBSERVATION:\n",
        "Scaling the data appears to reduce training times with GridCV noticeably.\n",
        "MSEs appears to be unchanged however!\n",
        "Also, SVR choose a linear kernel, rather than a polynomial one.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzfvHZCjUHss",
        "outputId": "9738f896-d3de-49d9-8462-00b781f7c545"
      },
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'OBSERVATION:\\nScaling the data appears to reduce training times with GridCV noticeably. \\nMSEs appears to be unchanged however!\\nAlso, SVR choose a linear kernel, rather than a polynomial one.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 327
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EXPERIMENT 2: Generate new features\n",
        "• Polynomial features (2nd and 3rd order)\n"
      ],
      "metadata": {
        "id": "kc4BjUAlBVMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2ND ORDER\n",
        "#generate polynomial features derived from X data\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "\n",
        "#SCALE ONLY THE FEATURES!\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "#degree=2 for 2nd order features\n",
        "poly_features = PolynomialFeatures(degree=3, include_bias=False)\n",
        "\n",
        "#fit and transform the features\n",
        "X_train = poly_features.fit_transform(X_train)\n",
        "X_test = poly_features.transform(X_test)\n",
        "\n",
        "#linear regression\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "t0 = time.time()\n",
        "%memit lin_reg.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "poly_lin_train_time = t1 - t0\n",
        "\n",
        "t0 = time.time()\n",
        "poly_y_pred_lin = lin_reg.predict(X_test)\n",
        "t1 = time.time()\n",
        "poly_lin_infer_time = t1 - t0\n",
        "\n",
        "#SVR\n",
        "param_grid = {'C': np.linspace(0.1, 1, 7), #higher C means less tolerance, lower means more tolerance\n",
        "              'kernel': ['linear', 'rbf', 'poly'],\n",
        "              'degree': [2, 3, 4,5],\n",
        "              'epsilon':np.linspace(0.01, 0.1, 10)}\n",
        "\n",
        "grid_search = GridSearchCV(SVR(), param_grid, cv=5, n_jobs=-1,verbose=True)\n",
        "\n",
        "t0 = time.time()\n",
        "%memit grid_search.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "poly_svr_train_time = t1 - t0\n",
        "\n",
        "t0 = time.time()\n",
        "poly_y_pred_svr = grid_search.best_estimator_.predict(X_test)\n",
        "t1 = time.time()\n",
        "poly_svr_infer_time = t1 - t0\n",
        "\n",
        "print(f\"Best SVR parameters: %s\" % grid_search.best_params_)\n",
        "\n",
        "#XGBoost\n",
        "\n",
        "param_grid = {'n_estimators': [300],\n",
        "              'n_jobs':[-1],\n",
        "              'gamma': [1,1.5],\n",
        "              'max_depth': [5,8],\n",
        "              'eta': [0.1,0.3],\n",
        "              'subsample':[1],\n",
        "              'colsample_bytree':[0.75],\n",
        "              'reg_lambda':[0.5,1],\n",
        "              'reg_alpha':[3,2.5],\n",
        "              }\n",
        "#Best XGBoost parameters:{'colsample_bytree': 0.75, 'eta': 0.3, 'gamma': 1, 'max_depth': 5, 'n_estimators': 300, 'n_jobs': -1, 'reg_alpha': 3, 'reg_lambda': 0.5, 'subsample': 1}\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBRegressor(), param_grid, cv=5, n_jobs=-1, scoring = \"neg_root_mean_squared_error\", verbose=True)\n",
        "\n",
        "t0 = time.time()\n",
        "%memit grid_search.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "poly_xgb_train_time = t1 - t0\n",
        "\n",
        "t0 = time.time()\n",
        "poly_y_pred_xgb = grid_search.best_estimator_.predict(X_test)\n",
        "t1 = time.time()\n",
        "poly_xgb_infer_time = t1 - t0\n",
        "\n",
        "print(f\"Best XGBoost parameters:%s\" % grid_search.best_params_)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIPUmwaQCtne",
        "outputId": "0282714b-d927-4107-8337-3bda8a38fc66"
      },
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 605.98 MiB, increment: 0.00 MiB\n",
            "Fitting 5 folds for each of 840 candidates, totalling 4200 fits\n",
            "peak memory: 606.23 MiB, increment: 0.00 MiB\n",
            "Best SVR parameters: {'C': 1.0, 'degree': 2, 'epsilon': 0.1, 'kernel': 'linear'}\n",
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
            "peak memory: 615.23 MiB, increment: 9.25 MiB\n",
            "Best XGBoost parameters:{'colsample_bytree': 0.75, 'eta': 0.1, 'gamma': 1, 'max_depth': 5, 'n_estimators': 300, 'n_jobs': -1, 'reg_alpha': 2.5, 'reg_lambda': 0.5, 'subsample': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate\n",
        "#lin reg\n",
        "poly_lin_reg_mse = mean_squared_error(y_test, poly_y_pred_lin)\n",
        "poly_lin_reg_r2 = r2_score(y_test, poly_y_pred_lin)\n",
        "\n",
        "#svr\n",
        "poly_svr_mse = mean_squared_error(y_test, poly_y_pred_svr)\n",
        "poly_svr_r2 = r2_score(y_test, poly_y_pred_svr)\n",
        "\n",
        "#xgb\n",
        "poly_xgb_mse = mean_squared_error(y_test, poly_y_pred_xgb)\n",
        "poly_xgb_r2 = r2_score(y_test, poly_y_pred_xgb)\n",
        "\n",
        "print(f\"Linear Regression MSE: {poly_lin_reg_mse}\")\n",
        "print(f\"Linear Regression R^2: {poly_lin_reg_r2}\")\n",
        "print(f\"SVR MSE: {poly_svr_mse}\")\n",
        "print(f\"SVR R^2: {poly_svr_r2}\")\n",
        "print(f\"XGBoost MSE: {poly_xgb_mse}\")\n",
        "print(f\"XGBoost R^2: {poly_xgb_r2}\")\n",
        "\n",
        "print(f\"Poly Linear Regression Training Time: {poly_lin_train_time} seconds\")\n",
        "print(f\"Poly SVR Training Time: {poly_svr_train_time} seconds\")\n",
        "print(f\"Poly XGBoost Training Time: {poly_xgb_train_time} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCt9dkVIXAB6",
        "outputId": "8d25d11b-1225-431e-f1bf-5ec3cb8de990"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression MSE: 16.242248176341487\n",
            "Linear Regression R^2: 0.0955078637213751\n",
            "SVR MSE: 5.305682591951444\n",
            "SVR R^2: 0.7045391666283836\n",
            "XGBoost MSE: 6.934081755189215\n",
            "XGBoost R^2: 0.6138574936308825\n",
            "Poly Linear Regression Training Time: 0.6842718124389648 seconds\n",
            "Poly SVR Training Time: 1.828301191329956 seconds\n",
            "Poly XGBoost Training Time: 2.4492132663726807 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"OBSERVATION:\n",
        "Introducing a polynomial feature appears to significantly worsen the performance\n",
        "of the linear regression model - this is expected since the purpose is to\n",
        "introduce non-linearity to the data.\n",
        "\n",
        "Polynomial features can introduce high multicollinearity (strong correlation among the features).\n",
        "This can make it difficult for linear regression to estimate the\n",
        "coefficients accurately and can lead to worse predictions.\n",
        "\n",
        "SVR performed the best out of the three models - even with a linear kernel.\n",
        "This may be because SVR does not assume a linear relationship between\n",
        "X and Y and captures more complex relationships within the data\n",
        "better than simple linear regression.\n",
        "\n",
        "Adding 2nd order polynomial increased SVR and XGBoost performance,\n",
        "but not linear regression - this indicates how XGBoost and SVR are better\n",
        "at non-linear relationships.\n",
        "\n",
        "However, increasing 2nd order to 3rd order made all models perform worse\n",
        "than the last experiment.\n",
        "\n",
        "2nd order results:\n",
        "Linear Regression MSE: 15.811879945458458\n",
        "Linear Regression R^2: 0.11947404600794098\n",
        "SVR MSE: 4.148939564413031\n",
        "SVR R^2: 0.7689554322059293\n",
        "XGBoost MSE: 5.490413432665133\n",
        "XGBoost R^2: 0.6942519458606913\n",
        "Poly Linear Regression Training Time: 0.5376052856445312 seconds\n",
        "Poly SVR Training Time: 5.408093452453613 seconds\n",
        "Poly XGBoost Training Time: 12.322922945022583 seconds\n",
        "\n",
        "3rd order results\n",
        "Linear Regression MSE: 16.242248176341487\n",
        "Linear Regression R^2: 0.0955078637213751\n",
        "SVR MSE: 5.305682591951444\n",
        "SVR R^2: 0.7045391666283836\n",
        "XGBoost MSE: 6.934081755189215\n",
        "XGBoost R^2: 0.6138574936308825\n",
        "Poly Linear Regression Training Time: 0.5849087238311768 seconds\n",
        "Poly SVR Training Time: 5.951260566711426 seconds\n",
        "Poly XGBoost Training Time: 30.620221853256226 seconds\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlcBKJvIXwOJ",
        "outputId": "b9e07293-e509-4589-d6d2-700fadcc987a"
      },
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'OBSERVATION:\\nIntroducing a polynomial feature appears to significantly worsen the performance\\nof the linear regression model - this is expected since the purpose is to\\nintroduce non-linearity to the data. \\n\\nPolynomial features can introduce high multicollinearity (strong correlation among the features). \\nThis can make it difficult for linear regression to estimate the \\ncoefficients accurately and can lead to worse predictions.\\n\\nSVR performed the best out of the three models - even with a linear kernel. \\nThis may be because SVR does not assume a linear relationship between \\nX and Y and captures more complex relationships within the data\\nbetter than simple linear regression.\\n\\nAdding 2nd order polynomial increased SVR and XGBoost performance, \\nbut not linear regression - this indicates how XGBoost and SVR are better\\nat non-linear relationships. \\n\\nHowever, increasing 2nd order to 3rd order made all models perform worse\\nthan the last experiment. \\n\\n2nd order results:\\nLinear Regression MSE: 15.811879945458458\\nLinear Regression R^2: 0.11947404600794098\\nSVR MSE: 4.148939564413031\\nSVR R^2: 0.7689554322059293\\nXGBoost MSE: 5.490413432665133\\nXGBoost R^2: 0.6942519458606913\\nPoly Linear Regression Training Time: 0.5376052856445312 seconds\\nPoly SVR Training Time: 5.408093452453613 seconds\\nPoly XGBoost Training Time: 12.322922945022583 seconds\\n\\n3rd order results\\nLinear Regression MSE: 16.242248176341487\\nLinear Regression R^2: 0.0955078637213751\\nSVR MSE: 5.305682591951444\\nSVR R^2: 0.7045391666283836\\nXGBoost MSE: 6.934081755189215\\nXGBoost R^2: 0.6138574936308825\\nPoly Linear Regression Training Time: 0.5849087238311768 seconds\\nPoly SVR Training Time: 5.951260566711426 seconds\\nPoly XGBoost Training Time: 30.620221853256226 seconds\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EXPERIMENT 3: FEATURE TRANSFORMATION"
      ],
      "metadata": {
        "id": "wlLVy7rPDMHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#USE PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "\n",
        "#apply scaling\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#apply pca\n",
        "pca = PCA(n_components=0.9)\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "#lin reg\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "t0 = time.time()\n",
        "%memit lin_reg.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "pca_lin_train_time = t1 - t0\n",
        "\n",
        "t0 = time.time()\n",
        "pca_y_pred_lin = lin_reg.predict(X_test)\n",
        "t1 = time.time()\n",
        "pca_lin_infer_time = t1 - t0\n",
        "\n",
        "#SVR\n",
        "param_grid = {'C': np.linspace(0.1, 1, 7), #higher C means less tolerance, lower means more tolerance\n",
        "              'kernel': ['linear', 'rbf', 'poly'],\n",
        "              'degree': [2, 3, 4,5],\n",
        "              'epsilon':np.linspace(0.01, 0.1, 10)}\n",
        "\n",
        "grid_search = GridSearchCV(SVR(), param_grid, cv=5, n_jobs=-1, verbose=True)\n",
        "\n",
        "t0 = time.time()\n",
        "%memit grid_search.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "pca_svr_train_time = t1 - t0\n",
        "\n",
        "t0 = time.time()\n",
        "pca_y_pred_svr = grid_search.best_estimator_.predict(X_test)\n",
        "t1 = time.time()\n",
        "pca_svr_infer_time = t1 - t0\n",
        "\n",
        "print(f\"Best SVR parameters: %s\" % grid_search.best_params_)\n",
        "\n",
        "#XGBoost\n",
        "\n",
        "param_grid = {'n_estimators': [300],\n",
        "              'n_jobs':[-1],\n",
        "              'gamma': [1,1.5],\n",
        "              'max_depth': [5,8],\n",
        "              'eta': [0.1,0.3],\n",
        "              'subsample':[1],\n",
        "              'colsample_bytree':[0.75],\n",
        "              'reg_lambda':[0.5,1],\n",
        "              'reg_alpha':[3,2.5],\n",
        "              }\n",
        "#Best XGBoost parameters:{'colsample_bytree': 0.75, 'eta': 0.3, 'gamma': 1, 'max_depth': 5, 'n_estimators': 300, 'n_jobs': -1, 'reg_alpha': 3, 'reg_lambda': 0.5, 'subsample': 1}\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBRegressor(), param_grid, cv=5, n_jobs=-1, scoring = \"neg_root_mean_squared_error\", verbose=True)\n",
        "\n",
        "t0 = time.time()\n",
        "%memit grid_search.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "pca_xgb_train_time = t1 - t0\n",
        "\n",
        "t0 = time.time()\n",
        "pca_y_pred_xgb = grid_search.best_estimator_.predict(X_test)\n",
        "t1 = time.time()\n",
        "pca_xgb_infer_time = t1 - t0\n",
        "\n",
        "print(f\"Best XGBoost parameters:%s\" % grid_search.best_params_)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UheHHhIWJk2y",
        "outputId": "de67e94e-3e3f-42cc-9850-61129064b248"
      },
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 597.74 MiB, increment: 0.00 MiB\n",
            "Fitting 5 folds for each of 840 candidates, totalling 4200 fits\n",
            "peak memory: 597.74 MiB, increment: 0.00 MiB\n",
            "Best SVR parameters: {'C': 1.0, 'degree': 3, 'epsilon': 0.1, 'kernel': 'poly'}\n",
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
            "peak memory: 597.74 MiB, increment: 0.00 MiB\n",
            "Best XGBoost parameters:{'colsample_bytree': 0.75, 'eta': 0.3, 'gamma': 1, 'max_depth': 5, 'n_estimators': 300, 'n_jobs': -1, 'reg_alpha': 3, 'reg_lambda': 1, 'subsample': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate\n",
        "#lin reg\n",
        "pca_lin_reg_mse = mean_squared_error(y_test, pca_y_pred_lin)\n",
        "pca_lin_reg_r2 = r2_score(y_test, pca_y_pred_lin)\n",
        "\n",
        "#svr\n",
        "pca_svr_mse = mean_squared_error(y_test, pca_y_pred_svr)\n",
        "pca_svr_r2 = r2_score(y_test, pca_y_pred_svr)\n",
        "\n",
        "#xgb\n",
        "pca_xgb_mse = mean_squared_error(y_test, pca_y_pred_xgb)\n",
        "pca_xgb_r2 = r2_score(y_test, pca_y_pred_xgb)\n",
        "\n",
        "print(f\"Linear Regression MSE: {pca_lin_reg_mse}\")\n",
        "print(f\"Linear Regression R^2: {pca_lin_reg_r2}\")\n",
        "print(f\"SVR MSE: {pca_svr_mse}\")\n",
        "print(f\"SVR R^2: {pca_svr_r2}\")\n",
        "print(f\"XGBoost MSE: {pca_xgb_mse}\")\n",
        "print(f\"XGBoost R^2: {pca_xgb_r2}\")\n",
        "\n",
        "print(f\"PCA Linear Regression Training Time: {pca_lin_train_time} seconds\")\n",
        "print(f\"PCA SVR Training Time: {pca_svr_train_time} seconds\")\n",
        "print(f\"PCA XGBoost Training Time: {pca_xgb_train_time} seconds\")\n",
        "\n",
        "print(f\"PCA reduced to {pca.n_components_} components! \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQJBO4trc_6V",
        "outputId": "32af3ff8-8c1c-4b40-b9cf-9f7b668e2876"
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression MSE: 5.839949811238412\n",
            "Linear Regression R^2: 0.6747870970090805\n",
            "SVR MSE: 5.935121810508435\n",
            "SVR R^2: 0.6694871949266188\n",
            "XGBoost MSE: 6.289780824268823\n",
            "XGBoost R^2: 0.6497370787158678\n",
            "PCA Linear Regression Training Time: 0.6138339042663574 seconds\n",
            "PCA SVR Training Time: 1.6256346702575684 seconds\n",
            "PCA XGBoost Training Time: 0.9283638000488281 seconds\n",
            "PCA reduced to 6 components! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"OBSERVATION:\n",
        "Reducing PCA to capture 90% of variance reduced the features to 6 components (out of 9).\n",
        "However, this also appears to raise MSE for XGBoost, while lowering SVR and Linear regression.\n",
        "Further experimentation with XGBoost parameters may be needed.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMVJwu5cgDvV",
        "outputId": "fdffde23-c5cc-4a5e-a2ca-ceeca5fc9c7b"
      },
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'OBSERVATION:\\nReducing PCA to capture 90% of variance reduced the features to 6 components (out of 9).\\nHowever, this also appears to raise MSE for XGBoost, while lowering SVR and Linear regression.\\nFurther experimentation with XGBoost parameters may be needed.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EXPERIMENT 4: HANDLING NOISE\n",
        "Introduce synthetic noise:\n",
        "\n",
        "• Add a random continuous feature (you can use random.Generator.uniform)\n",
        "\n",
        "• Add a random discrete categorical feature"
      ],
      "metadata": {
        "id": "lvl-fdBpjvEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Introduce synthetic noise:\n",
        "#Add a random continuous feature using random.Generator.uniform\n",
        "\n",
        "\n",
        "noise = np.random.rand(len(data))\n",
        "\n",
        "#random discrete categorical feature, 2 classes\n",
        "random_categories = np.random.randint(0, 2, size=len(data))\n",
        "data['RANDOM_CAT'] = random_categories\n",
        "data['NOISE'] = noise\n",
        "#display(data)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "\n",
        "#apply scaling\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#lin reg\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "t0 = time.time()\n",
        "%memit lin_reg.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "noise_lin_train_time = t1 - t0\n",
        "\n",
        "t0 = time.time()\n",
        "noise_y_pred_lin = lin_reg.predict(X_test)\n",
        "t1 = time.time()\n",
        "noise_lin_infer_time = t1 - t0\n",
        "\n",
        "#SVR\n",
        "param_grid = {'C': np.linspace(0.1, 1, 7), #higher C means less tolerance, lower means more tolerance\n",
        "              'kernel': ['linear', 'rbf', 'poly'],\n",
        "              'degree': [2, 3, 4,5],\n",
        "              'epsilon':np.linspace(0.01, 0.1, 10)}\n",
        "\n",
        "grid_search = GridSearchCV(SVR(), param_grid, cv=5, n_jobs=-1, verbose=True)\n",
        "\n",
        "t0 = time.time()\n",
        "%memit grid_search.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "noise_svr_train_time = t1 - t0\n",
        "\n",
        "t0 = time.time()\n",
        "noise_y_pred_svr = grid_search.best_estimator_.predict(X_test)\n",
        "t1 = time.time()\n",
        "noise_svr_infer_time = t1 - t0\n",
        "\n",
        "print(f\"Best SVR parameters: %s\" % grid_search.best_params_)\n",
        "\n",
        "#XGBoost\n",
        "\n",
        "param_grid = {'n_estimators': [300],\n",
        "              'n_jobs':[-1],\n",
        "              'gamma': [1,1.5],\n",
        "              'max_depth': [5,8],\n",
        "              'eta': [0.1,0.3],\n",
        "              'subsample':[1],\n",
        "              'colsample_bytree':[0.75],\n",
        "              'reg_lambda':[0.5,1],\n",
        "              'reg_alpha':[3,2.5],\n",
        "              }\n",
        "#Best XGBoost parameters:{'colsample_bytree': 0.75, 'eta': 0.3, 'gamma': 1, 'max_depth': 5, 'n_estimators': 300, 'n_jobs': -1, 'reg_alpha': 3, 'reg_lambda': 0.5, 'subsample': 1}\n",
        "\n",
        "grid_search = GridSearchCV(xgb.XGBRegressor(), param_grid, cv=5, n_jobs=-1, scoring = \"neg_root_mean_squared_error\", verbose=True)\n",
        "\n",
        "t0 = time.time()\n",
        "%memit grid_search.fit(X_train, y_train)\n",
        "t1 = time.time()\n",
        "noise_xgb_train_time = t1 - t0\n",
        "\n",
        "t0 = time.time()\n",
        "noise_y_pred_xgb = grid_search.best_estimator_.predict(X_test)\n",
        "t1 = time.time()\n",
        "noise_xgb_infer_time = t1 - t0\n",
        "\n",
        "print(f\"Best XGBoost parameters:%s\" % grid_search.best_params_)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xO32G0Dj96c",
        "outputId": "87f92246-a859-4352-b5a3-fdd6a26c1221"
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 597.74 MiB, increment: 0.00 MiB\n",
            "Fitting 5 folds for each of 840 candidates, totalling 4200 fits\n",
            "peak memory: 597.74 MiB, increment: 0.00 MiB\n",
            "Best SVR parameters: {'C': 1.0, 'degree': 2, 'epsilon': 0.01, 'kernel': 'linear'}\n",
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
            "peak memory: 597.74 MiB, increment: 0.00 MiB\n",
            "Best XGBoost parameters:{'colsample_bytree': 0.75, 'eta': 0.3, 'gamma': 1.5, 'max_depth': 5, 'n_estimators': 300, 'n_jobs': -1, 'reg_alpha': 3, 'reg_lambda': 1, 'subsample': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate\n",
        "#lin reg\n",
        "noise_lin_reg_mse = mean_squared_error(y_test, noise_y_pred_lin)\n",
        "noise_lin_reg_r2 = r2_score(y_test, noise_y_pred_lin)\n",
        "\n",
        "#svr\n",
        "noise_svr_mse = mean_squared_error(y_test, noise_y_pred_svr)\n",
        "noise_svr_r2 = r2_score(y_test, noise_y_pred_svr)\n",
        "\n",
        "#xgb\n",
        "noise_xgb_mse = mean_squared_error(y_test, noise_y_pred_xgb)\n",
        "noise_xgb_r2 = r2_score(y_test, noise_y_pred_xgb)\n",
        "\n",
        "print(f\"Linear Regression MSE: {noise_lin_reg_mse}\")\n",
        "print(f\"Linear Regression R^2: {noise_lin_reg_r2}\")\n",
        "print(f\"SVR MSE: {noise_svr_mse}\")\n",
        "print(f\"SVR R^2: {noise_svr_r2}\")\n",
        "print(f\"XGBoost MSE: {noise_xgb_mse}\")\n",
        "print(f\"XGBoost R^2: {noise_xgb_r2}\")\n",
        "\n",
        "print(f\"Noisy Linear Regression Training Time: {noise_lin_train_time} seconds\")\n",
        "print(f\"Noisy SVR Training Time: {noise_svr_train_time} seconds\")\n",
        "print(f\"Noisy XGBoost Training Time: {noise_xgb_train_time} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2vMOcaEm1rS",
        "outputId": "bcfe39c3-9c1d-4b62-daf2-596a918c95d9"
      },
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression MSE: 5.770998488020319\n",
            "Linear Regression R^2: 0.6786268320605133\n",
            "SVR MSE: 7.273371059388836\n",
            "SVR R^2: 0.5949632799579863\n",
            "XGBoost MSE: 6.547074497418209\n",
            "XGBoost R^2: 0.6354090065456097\n",
            "Noisy Linear Regression Training Time: 0.662168025970459 seconds\n",
            "Noisy SVR Training Time: 1.5605535507202148 seconds\n",
            "Noisy XGBoost Training Time: 0.9128923416137695 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Efficiency"
      ],
      "metadata": {
        "id": "rIzqyTi5n6gL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TIME COMPARISONS\n",
        "time_df = pd.DataFrame(columns=['Model Variant', 'Training Time', 'Inference Time'])\n",
        "\n",
        "#Linear Regression\n",
        "time_df.loc[len(time_df)] = ['BASE Linear Regression', base_lin_train_time, base_lin_infer_time]\n",
        "time_df.loc[len(time_df)] = ['SCALED Linear Regression', scale_lin_train_time, scale_lin_infer_time]\n",
        "time_df.loc[len(time_df)] = ['POLY Linear Regression', poly_lin_train_time, poly_lin_infer_time]\n",
        "time_df.loc[len(time_df)] = ['PCA Linear Regression', pca_lin_train_time, pca_lin_infer_time]\n",
        "time_df.loc[len(time_df)] = ['NOISY Linear Regression', noise_lin_train_time, noise_lin_infer_time]\n",
        "\n",
        "#SVR\n",
        "time_df.loc[len(time_df)] = ['BASE SVR', base_svr_train_time, base_svr_infer_time]\n",
        "time_df.loc[len(time_df)] = ['SCALED SVR', scale_svr_train_time, scale_svr_infer_time]\n",
        "time_df.loc[len(time_df)] = ['POLY SVR', poly_svr_train_time, poly_svr_infer_time]\n",
        "time_df.loc[len(time_df)] = ['PCA SVR', pca_svr_train_time, pca_svr_infer_time]\n",
        "time_df.loc[len(time_df)] = ['NOISY SVR', noise_svr_train_time, noise_svr_infer_time]\n",
        "\n",
        "#XGBoost\n",
        "time_df.loc[len(time_df)] = ['BASE XGBoost', base_xgb_train_time, base_xgb_infer_time]\n",
        "time_df.loc[len(time_df)] = ['SCALED XGBoost', scale_xgb_train_time, scale_xgb_infer_time]\n",
        "time_df.loc[len(time_df)] = ['POLY XGBoost', poly_xgb_train_time, poly_xgb_infer_time]\n",
        "time_df.loc[len(time_df)] = ['PCA XGBoost', pca_xgb_train_time, pca_xgb_infer_time]\n",
        "time_df.loc[len(time_df)] = ['NOISY XGBoost', noise_xgb_train_time, noise_xgb_infer_time]\n",
        "\n",
        "display(time_df)\n",
        "\n",
        "\"\"\"\n",
        "If required to deploy a model, which trade-offs are necessary?\n",
        "\n",
        "If speed is important: Linear regression offers the fastest speeds, and decent\n",
        "accuracy for this dataset (except for when adding Polynomial features!).\n",
        "\n",
        "If accuracy is important: SVR outperformed linear and XGBoost in some cases,\n",
        "although linear had good accuracy as well, along with its speed.\n",
        "XGBoost requires much more hyperparameter experimentation to be considered as the best.\n",
        "\n",
        "If interpretability is important: Linear Regression is the preferred choice,\n",
        "as it offers a clearer understanding of feature importance and relationships.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "eLuYnTJS1yCe",
        "outputId": "9ef4af16-28a5-4dde-8628-848a3e4a2ab6"
      },
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               Model Variant  Training Time  Inference Time\n",
              "0     BASE Linear Regression       0.673842        0.000947\n",
              "1   SCALED Linear Regression       0.610964        0.000310\n",
              "2     POLY Linear Regression       0.684272        0.005239\n",
              "3      PCA Linear Regression       0.613834        0.000323\n",
              "4    NOISY Linear Regression       0.662168        0.000340\n",
              "5                   BASE SVR       2.388616        0.000661\n",
              "6                 SCALED SVR       1.558079        0.000751\n",
              "7                   POLY SVR       1.828301        0.000646\n",
              "8                    PCA SVR       1.625635        0.000801\n",
              "9                  NOISY SVR       1.560554        0.000773\n",
              "10              BASE XGBoost       2.022057        0.001509\n",
              "11            SCALED XGBoost       0.936276        0.001146\n",
              "12              POLY XGBoost       2.449213        0.003936\n",
              "13               PCA XGBoost       0.928364        0.001004\n",
              "14             NOISY XGBoost       0.912892        0.001105"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Variant</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BASE Linear Regression</td>\n",
              "      <td>0.673842</td>\n",
              "      <td>0.000947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SCALED Linear Regression</td>\n",
              "      <td>0.610964</td>\n",
              "      <td>0.000310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>POLY Linear Regression</td>\n",
              "      <td>0.684272</td>\n",
              "      <td>0.005239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PCA Linear Regression</td>\n",
              "      <td>0.613834</td>\n",
              "      <td>0.000323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NOISY Linear Regression</td>\n",
              "      <td>0.662168</td>\n",
              "      <td>0.000340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BASE SVR</td>\n",
              "      <td>2.388616</td>\n",
              "      <td>0.000661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SCALED SVR</td>\n",
              "      <td>1.558079</td>\n",
              "      <td>0.000751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>POLY SVR</td>\n",
              "      <td>1.828301</td>\n",
              "      <td>0.000646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>PCA SVR</td>\n",
              "      <td>1.625635</td>\n",
              "      <td>0.000801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NOISY SVR</td>\n",
              "      <td>1.560554</td>\n",
              "      <td>0.000773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>BASE XGBoost</td>\n",
              "      <td>2.022057</td>\n",
              "      <td>0.001509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>SCALED XGBoost</td>\n",
              "      <td>0.936276</td>\n",
              "      <td>0.001146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>POLY XGBoost</td>\n",
              "      <td>2.449213</td>\n",
              "      <td>0.003936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>PCA XGBoost</td>\n",
              "      <td>0.928364</td>\n",
              "      <td>0.001004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NOISY XGBoost</td>\n",
              "      <td>0.912892</td>\n",
              "      <td>0.001105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nIf required to deploy a model, which trade-offs are necessary?\\n\\nIf inference speed is important: Consider deploying Linear Regression or XGBoost with scaled hyperparameters for faster predictions.\\nIf accuracy is important: Choose SVR or XGBoost with a focus on maximizing performance, even if it leads to slower inference or larger model size.\\nIf interpretability is important: Linear Regression might be the preferred choice, as it offers a clear understanding of feature importance and relationships.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 337
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summarization of findings\n"
      ],
      "metadata": {
        "id": "jv8JW08B54BE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SUMMARIZATION TABLE\n",
        "mse_df = pd.DataFrame(columns=['Model Variant', 'MSE', 'R-squared'])\n",
        "#linear reg errors\n",
        "mse_df.loc[len(mse_df)] = ['BASE Linear Regression MSE', lin_reg_mse, lin_reg_r2]\n",
        "mse_df.loc[len(mse_df)] = ['SCALED Linear Regression MSE', scale_lin_reg_mse, scale_lin_reg_r2]\n",
        "mse_df.loc[len(mse_df)] = ['POLY Linear Regression MSE', poly_lin_reg_mse, poly_lin_reg_r2]\n",
        "mse_df.loc[len(mse_df)] = ['PCA Linear Regression MSE', pca_lin_reg_mse, pca_lin_reg_r2]\n",
        "mse_df.loc[len(mse_df)] = ['NOISY Linear Regression MSE', noise_lin_reg_mse, noise_lin_reg_r2]\n",
        "\n",
        "#SVR\n",
        "mse_df.loc[len(mse_df)] = ['BASE SVR MSE', svr_mse, svr_r2]\n",
        "mse_df.loc[len(mse_df)] = ['SCALED SVR MSE', scale_svr_mse, scale_svr_r2]\n",
        "mse_df.loc[len(mse_df)] = ['POLY SVR MSE', poly_svr_mse, poly_svr_r2]\n",
        "mse_df.loc[len(mse_df)] = ['PCA SVR MSE', pca_svr_mse, pca_svr_r2]\n",
        "mse_df.loc[len(mse_df)] = ['NOISY SVR MSE', noise_svr_mse, noise_svr_r2]\n",
        "\n",
        "#XGBoost\n",
        "mse_df.loc[len(mse_df)] = ['BASE XGBoost MSE', xgb_mse, xgb_r2]\n",
        "mse_df.loc[len(mse_df)] = ['SCALED XGBoost MSE', scale_xgb_mse, scale_xgb_r2]\n",
        "mse_df.loc[len(mse_df)] = ['POLY XGBoost MSE', poly_xgb_mse, poly_xgb_r2]\n",
        "mse_df.loc[len(mse_df)] = ['PCA XGBoost MSE', pca_xgb_mse, pca_xgb_r2]\n",
        "mse_df.loc[len(mse_df)] = ['NOISY XGBoost MSE', noise_xgb_mse, noise_xgb_r2]\n",
        "\n",
        "display(mse_df)\n",
        "\n",
        "print(f\"Lowest MSE model variant: {mse_df.loc[mse_df['MSE'].idxmin()]['MSE']} {mse_df.loc[mse_df['MSE'].idxmin()]['Model Variant']} \")\n",
        "print(f\"Highest MSE model variant: {mse_df.loc[mse_df['MSE'].idxmax()]['MSE']} {mse_df.loc[mse_df['MSE'].idxmax()]['Model Variant']} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "8hXCUjzi58Je",
        "outputId": "8afb3786-eb8c-4b82-ab1b-1f5180bdb9f4"
      },
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   Model Variant        MSE  R-squared\n",
              "0     BASE Linear Regression MSE   6.021257   0.664691\n",
              "1   SCALED Linear Regression MSE   6.021257   0.664691\n",
              "2     POLY Linear Regression MSE  16.242248   0.095508\n",
              "3      PCA Linear Regression MSE   5.839950   0.674787\n",
              "4    NOISY Linear Regression MSE   5.770998   0.678627\n",
              "5                   BASE SVR MSE   6.761788   0.623452\n",
              "6                 SCALED SVR MSE   6.177534   0.655988\n",
              "7                   POLY SVR MSE   5.305683   0.704539\n",
              "8                    PCA SVR MSE   5.935122   0.669487\n",
              "9                  NOISY SVR MSE   7.273371   0.594963\n",
              "10              BASE XGBoost MSE   5.910050   0.670883\n",
              "11            SCALED XGBoost MSE   5.910050   0.670883\n",
              "12              POLY XGBoost MSE   6.934082   0.613857\n",
              "13               PCA XGBoost MSE   6.289781   0.649737\n",
              "14             NOISY XGBoost MSE   6.547074   0.635409"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Variant</th>\n",
              "      <th>MSE</th>\n",
              "      <th>R-squared</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BASE Linear Regression MSE</td>\n",
              "      <td>6.021257</td>\n",
              "      <td>0.664691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SCALED Linear Regression MSE</td>\n",
              "      <td>6.021257</td>\n",
              "      <td>0.664691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>POLY Linear Regression MSE</td>\n",
              "      <td>16.242248</td>\n",
              "      <td>0.095508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PCA Linear Regression MSE</td>\n",
              "      <td>5.839950</td>\n",
              "      <td>0.674787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NOISY Linear Regression MSE</td>\n",
              "      <td>5.770998</td>\n",
              "      <td>0.678627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BASE SVR MSE</td>\n",
              "      <td>6.761788</td>\n",
              "      <td>0.623452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SCALED SVR MSE</td>\n",
              "      <td>6.177534</td>\n",
              "      <td>0.655988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>POLY SVR MSE</td>\n",
              "      <td>5.305683</td>\n",
              "      <td>0.704539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>PCA SVR MSE</td>\n",
              "      <td>5.935122</td>\n",
              "      <td>0.669487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NOISY SVR MSE</td>\n",
              "      <td>7.273371</td>\n",
              "      <td>0.594963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>BASE XGBoost MSE</td>\n",
              "      <td>5.910050</td>\n",
              "      <td>0.670883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>SCALED XGBoost MSE</td>\n",
              "      <td>5.910050</td>\n",
              "      <td>0.670883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>POLY XGBoost MSE</td>\n",
              "      <td>6.934082</td>\n",
              "      <td>0.613857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>PCA XGBoost MSE</td>\n",
              "      <td>6.289781</td>\n",
              "      <td>0.649737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NOISY XGBoost MSE</td>\n",
              "      <td>6.547074</td>\n",
              "      <td>0.635409</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowest MSE model variant: 5.305682591951444 POLY SVR MSE \n",
            "Highest MSE model variant: 16.242248176341487 POLY Linear Regression MSE \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Final model choice\n",
        "\n",
        "it appears that SVR with added polynomial features (specifically, 2nd order) achieved the lowest MSE and highest R-squared compared to other model variants - therefore, this is my recomended model for the given dataset. This suggests that this model effectively captured the non-linear relationships introduced in the dataset, leading to improved predictive performance.\n",
        "\n",
        "The inclusion of polynomial features introduced non-linearity into the model, allowing it to better represent complex patterns in the data that the model previously s struggled with.\n",
        "\n",
        "##Proposed Further Refinements\n",
        "If more time, and patience, were available, a more extensive GridSearch over a wider range of values could potentially yield better results. Using techniques like RandomizedSearchCV or Bayesian Optimization would alternatively allow for a more efficient exploration of the hyperparameter space.\n",
        "\n",
        "Experimenting with other models, particularly  Ensemble Methods could potentially improve overall accuracy and stability.\n",
        "\n"
      ],
      "metadata": {
        "id": "rkmomlHP78CG"
      }
    }
  ]
}